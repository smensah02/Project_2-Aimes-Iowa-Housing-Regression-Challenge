{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 - Regression Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the price of homes at sale for the Ames Iowa Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration and Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Installations \n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('./Data/train (2).csv')\n",
    "df_ktest_original = pd.read_csv('./Data/test (2).csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.drop(['Id', 'PID'], axis=1)\n",
    "df_ktest = df_ktest_original.drop(['Id', 'PID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace spaces in column names and convert all columns to lowercase:\n",
    "df.columns = [x.lower().replace(' ','_') for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_object = df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers = df.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_object.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts the number of True values (which represent missing values), \n",
    "# sorts the values and returns ttop 15 columns with the highest number of missing values.\n",
    "df_numbers.isnull().sum().sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_numbers['lot_frontage'].fillna((0.0), inplace=True)\n",
    "df_numbers['garage_yr_blt'].fillna((0.0), inplace=True)\n",
    "df_numbers['mas_vnr_area'].fillna((0.0), inplace=True)\n",
    "df_numbers['bsmt_half_bath'].fillna((0.0), inplace=True)\n",
    "df_numbers['bsmt_full_bath'].fillna((0.0), inplace=True)\n",
    "df_numbers['garage_cars'].fillna((0.0), inplace=True)\n",
    "df_numbers['bsmtfin_sf_1'].fillna((0.0), inplace=True)\n",
    "df_numbers['bsmtfin_sf_2'].fillna((0.0), inplace=True)\n",
    "df_numbers['bsmt_unf_sf'].fillna((0.0), inplace=True)\n",
    "df_numbers['total_bsmt_sf'].fillna((0.0), inplace=True)\n",
    "df_numbers['garage_area'].fillna((0.0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers.isnull().sum().sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension\n",
    "features_list = [each for each in df_numbers.columns if each != 'saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_numbers[features_list]\n",
    "y = df_numbers['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers_corr = list(pd.concat([X_train, y_train],\n",
    "                          axis=1).corr()['saleprice'].sort_values(ascending=False).index[1:38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_ktest_numbers_corr = list(pd.concat([X_test, y_test],\n",
    "                          axis=1).corr()['saleprice'].sort_values(ascending=False).index[1:38])\n",
    "\n",
    "df_ktest = X_test[df_ktest_numbers_corr]\n",
    "df_ktest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_train[df_numbers_corr].corr(), vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[df_numbers_corr]\n",
    "X_test = X_test[df_numbers_corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing** in machine learning refers to the crucial initial phase of transforming raw data into a clean, structured, and suitable format for training and evaluating machine learning models. This process is essential because real-world data is often incomplete, inconsistent, noisy, or in a format incompatible with machine learning algorithms.\n",
    "\n",
    "\n",
    "**PolynomialFeatures()** is a preprocessing tool within scikit-learn's preprocessing module in machine learning. It is used to generate polynomial and interaction features from existing features in a dataset. It's primary purpose is to allow linear models (like Linear Regression) to capture non-linear relationships in the data.\n",
    "\n",
    "\n",
    "**StandardScaler()** in machine learning, particularly within the scikit-learn library, is a preprocessing technique used to standardize features by removing the mean and scaling to unit variance. This transformation results in a distribution with a mean of 0 and a standard deviation of 1. Many machine learning algorithms, especially those based on distance calculations (e.g., K-Nearest Neighbors, Support Vector Machines) or gradient descent (e.g., neural networks), are sensitive to the scale of features. StandardScaler ensures that all features contribute equally to the model, preventing features with larger numerical ranges from dominating those with smaller ranges.\n",
    "\n",
    "In machine learning, **LogisticRegression()** typically often found within libraries like scikit-learn in Python. It is a supervised learning algorithm primarily used for binary classification tasks, although extensions exist for multi-class classification (Multinomial and Ordinal Logistic Regression). It models the probability of a binary outcome (e.g., spam/not spam, disease/no disease) based on a set of input features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine learning (ML) **pipeline** is a structured means of automating the machine learning workflow by enabling data to be transformed and correlated into a model that can then be analyzed to achieve outputs\n",
    "\n",
    "**Lasso** (Least Absolute Shrinkage and Selection Operator) is a regularization technique in machine learning, particularly useful for linear regression models. It performs both feature selection and regularization, helping to prevent overfitting and improve model interpretability. Lasso achieves this by adding a penalty term to the model's loss function, which shrinks some coefficients towards zero, effectively removing some features from the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCv model using only num variables and replacing nulls with 0 for each variables\n",
    "pipe = Pipeline([\n",
    "    ('pf', PolynomialFeatures()),\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lcv', LassoCV(n_alphas=500, max_iter=1000))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['lcv'].alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace spaces in column names and convert all columns to lowercase:\n",
    "df_ktest.columns = [x.lower().replace(' ','_') for x in df_ktest.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers =df_ktest.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers.isnull().sum().sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers['lot_frontage'].fillna((0.0), inplace=True)\n",
    "df_ktest_numbers['garage_yr_blt'].fillna((0.0), inplace=True)\n",
    "df_ktest_numbers['mas_vnr_area'].fillna((0.0), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers.isnull().sum().sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably need to drop 'id' from both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[sorted(X_train.columns)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ktest_numbers[sorted(df_ktest_numbers)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^ (Symmetric difference) This is the symmetric difference operator for sets in Python.\n",
    "# It returns a new set containing all elements that are in either of the two sets but not in their intersection. \n",
    "# In other words, it reveals the column names that are unique to one set or the other. \n",
    "\n",
    "set(df_ktest_numbers.columns) ^ set(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers.columns\n",
    "df_ktest_numbers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktest_numbers = df_ktest_numbers[pipe.feature_names_in_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe.predict(df_ktest_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_ktest_original['Id'][:513]\n",
    "\n",
    "preds_df = pd.DataFrame({\n",
    "    'Id': ids,\n",
    "    'saleprice': preds\n",
    "})\n",
    "preds_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = str(datetime.datetime.now())\n",
    "\n",
    "f'predictions_{now}'\n",
    "\n",
    "now1 = str(datetime.datetime.now())\n",
    "preds_df.to_csv('kaggle_Preds_{now1}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('kaggle_Preds_{now1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
